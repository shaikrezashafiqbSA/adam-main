{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rag V2 Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RAG.RAG import RAG\n",
    "rag = RAG(\n",
    "    data_models=[\n",
    "                #  {\"name\":\"travel\",\n",
    "                #   \"type\":\"db\",\n",
    "                #   \"data\": [\"flights\", \"accommodations\", \"activities\", \"services\", \"insurance\"],\n",
    "                #   \"LLM_model\":\"gemini-pro-ultra\",\n",
    "                #   \"embedding_model\":\"models/embedding-001\"},\n",
    "\n",
    "                  {\"name\":\"islam\",\n",
    "                   \"type\":\"db\",\n",
    "                   \"data\": [\"hadith\", \"quran\"],\n",
    "                   \"LLM_model\":\"gemini-pro\",\n",
    "                   \"embedding_model\":\"models/embedding-001\"},\n",
    "                ],\n",
    "        ) \n",
    "\n",
    "result = rag.query(\n",
    "    # query_text=\"plan me a travel package: i want replicate the experience of Moses travelling from Egypt to sinai, with a side quest with Al-khidr next month\",\n",
    "    query_text=\"Tell me the narration on Al-Khidr and Musa (Moses) in the Hadith that supplements the Quran\",\n",
    "    data_sources=[\"islam\"], #[\"islam\", \"travel\", \"finance\"]\n",
    "    instruction_mapper = {\n",
    "                            \"models\": [ \n",
    "                                {\"type\": \"NLP\", \"model\": \"spaCy\"},           # favor rule-based extraction for efficiency.\n",
    "                                # {\"type\": \"LLM\", \"model\": \"gemini-pro-ultra\"} # rely on the LLM to interpret subtleties.\n",
    "                            ] # Complex Query: The list format above would enable a sequential hybrid approach leveraging both techniques.\n",
    "                         } \n",
    ")\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Hadith found containing 'Al-Khidr'.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Hadiths found in Hisn al-Muslim section.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import api_key, Completion  # Assuming you're using the OpenAI API\n",
    "def construct_prompt(instruction, text_chunk):\n",
    "    return f\"Instruction: {instruction} \\nDocument Text: {text_chunk} \\nAnswer:\"\n",
    "\n",
    "def RagParse(parsing_instruction, result_type=\"markdown\",):\n",
    "    \"\"\"\n",
    "    RagParse function primarily leveraging an LLM for parsing instruction execution. \n",
    "    \"\"\"\n",
    "    # ... (Setup your API Key if needed) ...\n",
    "\n",
    "    def load_data(data_path):\n",
    "        try:\n",
    "            with open(data_path, \"r\") as f:\n",
    "                document_text = f.read() \n",
    "            return {\"document_text\": document_text}  \n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: File not found at {data_path}\")\n",
    "            return {}\n",
    "\n",
    "    def process_document(document):\n",
    "        benefits_strings = []\n",
    "\n",
    "        # (1) Split document into potential sections or chunks \n",
    "        document_chunks = split_document(document[\"document_text\"])  \n",
    "\n",
    "        for chunk in document_chunks:\n",
    "            # (2) LLM Prompt Construction for Each Chunk\n",
    "            prompt = construct_prompt(parsing_instruction, chunk) \n",
    "\n",
    "            # (3) Call Gemini API\n",
    "            response = Completion.create(\n",
    "                engine=\"gemini-pro-ultra-0225\",  # Or your preferred engine\n",
    "                prompt=prompt,\n",
    "                max_tokens=100,  # Adjust as needed\n",
    "                # ... other API parameters as needed ...\n",
    "            )\n",
    "\n",
    "            # (4) Extract and Process Response \n",
    "            extracted_strings = extract_benefits_strings(response.choices[0].text)\n",
    "            benefits_strings.extend(extracted_strings)\n",
    "\n",
    "        return format_output(benefits_strings, result_type)\n",
    "\n",
    "    return process_document(load_data(\"./policy.pdf\")) # Change the path as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCP AI Platform \n",
    "Notebooks are pre-installed with the Rag V2 framework. This notebook demonstrates how to use the Rag V2 framework to fine-tune a Rag model on a custom dataset that is stored in a Google Cloud Storage bucket.\n",
    "- The dataset should be in the form of a jsonl file with the following format:\n",
    "```\n",
    "{\"text\": \"question\", \"meta\": {\"name\": \"document_name\", \"section\": \"document_section\"}}\n",
    "{\"text\": \"answer\", \"meta\": {\"name\": \"document_name\", \"section\": \"document_section\"}}\n",
    "```\n",
    "\n",
    "- The model is fine-tuned on the dataset using the `rag_v2` framework.\n",
    "- The fine-tuned model is saved to a Google Cloud Storage bucket.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps\n",
    "1. Load the dataset from a Google Cloud Storage bucket.\n",
    "2. Fine-tune the Rag model on the dataset.\n",
    "3. Save the fine-tuned model to a Google Cloud Storage bucket.\n",
    "4. Test the fine-tuned model.\n",
    "5. Inference using the fine-tuned model + database of documents.\n",
    "\n",
    "    a) Load the documents from a Google Cloud Storage bucket.\n",
    "\n",
    "    b) Index the documents using embedding-model (LLM/NLP)\n",
    "\n",
    "        i) Generate embeddings for the documents.\n",
    "\n",
    "        ii) Index the embeddings\n",
    "\n",
    "    c) Query the fine-tuned model with a question.\n",
    "\n",
    "        i) Retrieve the top-k documents.\n",
    "\n",
    "        ii) Retrieve the answer from the indexed documents.\n",
    "\n",
    "    d) Retrieve the answer from the indexed documents.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) GCP API\n",
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Master Database']\n"
     ]
    }
   ],
   "source": [
    "import gspread\n",
    "\n",
    "gc = gspread.service_account(filename='./gdrive/phrasal-ability-419201-d527372ace3b.json') \n",
    "# gc = gspread.service_account(filename='./gdrive/lunar-landing-389714-369d3f1b2a09.json')\n",
    "sheets = gc.openall()\n",
    "print([sheet.title for sheet in sheets]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gdrive.gdrive_handler import GspreadHandler\n",
    "gspread_handler = GspreadHandler(credentials_filepath='./gdrive/phrasal-ability-419201-d527372ace3b.json')\n",
    "df = gspread_handler.get_sheet_as_df(sheet_name=\"Master Database\", worksheet_name=\"partners\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meta</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wang Gunung Trail Run 2.0</td>\n",
       "      <td>WANG GUNUNG\\nTRAIL RUN 2.0\\nCONQUER THE AGRO ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nakawan Ultra</td>\n",
       "      <td>NAKAWAUN ULTRA\\nTHE THRILL OF NORTHERN TRAILS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Perlis Eco X Venture</td>\n",
       "      <td>PERLIS\\nECO X VENTURE \\nLETS TRAVEL WITH OUR ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perlis EcoXVenture Experiences</td>\n",
       "      <td>Visit Perlis 2024 - 2025\\nPerlis Indahnya Mem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ClubRock Perlis 3D2N</td>\n",
       "      <td>MARK HISHAM\\nGENERAL MANAGER\\n\\nm +6012 899 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Perlis Smart Leisure Travels</td>\n",
       "      <td>Penang MATTA Fair Special\\n30.09 to 01.10.23\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Perlis Eco Adventure Tours</td>\n",
       "      <td>**unicastanaholidays**\\ns/bnd (KPK/LN: 1031)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Perlis Nature &amp; Homestay Packages</td>\n",
       "      <td>PERLIS NATURE &amp; HOMESTAY PACKAGES\\n\\n**Perlis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Smart Leisure Travels Jom Discover Perlis</td>\n",
       "      <td>Explore \\nPerlis\\n&lt;center&gt; _Inilah Masanya_\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2D1N Harumanis Tour</td>\n",
       "      <td>MATTA FAIR\\n\\nSMART LEISURE TRAVELS\\nSEE TRAV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gua Kelam Chalet Perlis</td>\n",
       "      <td>Our Facilities\\n\\n- Swimming Pool\\n- Lounge\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         meta  \\\n",
       "0                   Wang Gunung Trail Run 2.0   \n",
       "1                               Nakawan Ultra   \n",
       "2                        Perlis Eco X Venture   \n",
       "3              Perlis EcoXVenture Experiences   \n",
       "4                        ClubRock Perlis 3D2N   \n",
       "5                Perlis Smart Leisure Travels   \n",
       "6                  Perlis Eco Adventure Tours   \n",
       "7           Perlis Nature & Homestay Packages   \n",
       "8   Smart Leisure Travels Jom Discover Perlis   \n",
       "9                         2D1N Harumanis Tour   \n",
       "10                    Gua Kelam Chalet Perlis   \n",
       "\n",
       "                                                 data  \n",
       "0    WANG GUNUNG\\nTRAIL RUN 2.0\\nCONQUER THE AGRO ...  \n",
       "1    NAKAWAUN ULTRA\\nTHE THRILL OF NORTHERN TRAILS...  \n",
       "2    PERLIS\\nECO X VENTURE \\nLETS TRAVEL WITH OUR ...  \n",
       "3    Visit Perlis 2024 - 2025\\nPerlis Indahnya Mem...  \n",
       "4    MARK HISHAM\\nGENERAL MANAGER\\n\\nm +6012 899 0...  \n",
       "5    Penang MATTA Fair Special\\n30.09 to 01.10.23\\...  \n",
       "6    **unicastanaholidays**\\ns/bnd (KPK/LN: 1031)\\...  \n",
       "7    PERLIS NATURE & HOMESTAY PACKAGES\\n\\n**Perlis...  \n",
       "8    Explore \\nPerlis\\n<center> _Inilah Masanya_\\n...  \n",
       "9    MATTA FAIR\\n\\nSMART LEISURE TRAVELS\\nSEE TRAV...  \n",
       "10   Our Facilities\\n\\n- Swimming Pool\\n- Lounge\\n...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
