{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Librarian\n",
    "\n",
    "Librarian is a data-centric conversational model (RAG).\n",
    "\n",
    "It is able to embody archetypes (specialists) and is able to converse with the user to retrieve information from these databases.\n",
    "\n",
    "Such a data model centric design allows for the user to query information from a variety of databases, and the librarian is able to retrieve and cross-reference information from these databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading specialist: TRAVELLER ...\n",
      "TRAVELLER embedding: TEST - CLIENT - LOADED\n",
      "TRAVELLER embedding: TEST - CLIENT REQUEST - LOADED\n",
      "TRAVELLER embedding: TEST - FLIGHTS - LOADED\n",
      "TRAVELLER embedding: TEST - ACCOMODATIONS - LOADED\n",
      "TRAVELLER embedding: TEST - ACTIVITIES - LOADED\n",
      "TRAVELLER embedding: TEST - SERVICES - LOADED\n",
      "TRAVELLER loaded\n"
     ]
    }
   ],
   "source": [
    "from RAG.librarian import Librarian \n",
    "\n",
    "librarian = Librarian(librarian_LLM_model = \"GEMINI\")\n",
    "\n",
    "# SELECT SPECIALIST DATABASE\n",
    "librarian.select_specialist(specialist = \"traveller\", specialist_LLM_model = \"GEMINI\")\n",
    "\n",
    "# Ask librarian to get acquinted with the specialist database\n",
    "librarian.Traveller.load_data_model(reembed = False,\n",
    "                                    embed_id = 0,\n",
    "                                    data_model_keys = {\"TEST - CLIENT\":\"CLIENT ID\",\n",
    "                                                        \"TEST - CLIENT REQUEST\":\"CLIENT ID\",\n",
    "                                                        \"TEST - FLIGHTS\":\"FLIGHT ID\",\n",
    "                                                        \"TEST - ACCOMODATIONS\":\"ACCOMODATION ID\",\n",
    "                                                        \"TEST - ACTIVITIES\":\"ACTIVITY ID\",\n",
    "                                                        \"TEST - SERVICES\":\"SERVICE ID\",\n",
    "                                                        },\n",
    "                                    reembed_table = {\"TEST - CLIENT\":True,\n",
    "                                                    \"TEST - CLIENT REQUEST\":True,\n",
    "                                                    \"TEST - FLIGHTS\":True,\n",
    "                                                    \"TEST - ACCOMODATIONS\":True,\n",
    "                                                    \"TEST - ACTIVITIES\":True,\n",
    "                                                    \"TEST - SERVICES\":True,\n",
    "                                                    }\n",
    "\n",
    "                                    )\n",
    "\n",
    "# Data Model data quality to be checked (dropped all irrelevant data - invoice number, other ids, empty cells)\n",
    "# TODO: disintegrate services into 3 buckets so that fit into a day or half  day, etc\n",
    "# eg; tour: 3h cultural tour at arab str, 4h foodie tour, 6h hiking tour, 3 hr shopping tour \n",
    "# - HOW TO CLASSIFY THESE BUCKETS? best way? gotta see existing travel packages (and how they are classified)\n",
    "# - have to check with SME on data model - edit, modify buckets based on SmartWorld specialised needs\n",
    "# prompt engineering: include a free-and easy day if theres a gap in the schedule or Reserve 1 day for RR, etc\n",
    "\n",
    "# RAG ACCURACY: \n",
    "# - how to check if the RAG is accurate? \n",
    "# - how to check if the RAG is hallucinating? \n",
    "# - how to check if the RAG is giving irrelevant data?\n",
    "\n",
    "#TODO: services -> activity (attractions, shopping, dining,) \n",
    "# \n",
    "# services new table\n",
    "# Services: drivers is daily price, if 7 day, 7 x daily price, tourguides, translator, chef, bodyguard, VIP escort\n",
    "\n",
    "\n",
    "#TODO: costing has to be accurate, and also has to be based on the client's budget\n",
    "\n",
    "#TODO: itinerary has to be based on the client's preferences, and also has to be based on the client's historical preferences\n",
    "\n",
    "#TODO: flawed or hallucinated responses have to be stored and set as bad example for future response \n",
    "# eg; this package is hallucinating dicsount vouchers at orchard road - this is a bad example, and should be flagged as such\n",
    "\n",
    "#TODO: streamline library (clear irrevelant backend codes; ADAM_llama_index_RAG, crypto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _*Generate*_ : travel package from customer/agent prompt  + inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using initial query: Shaik from Kuala Lumpur wants to go Singapore for 5 days for 2 pax. Budget: $2000. Make one day specifically for Little India. Make leftover days for OTHER casual activities.\n",
      "Token size of the prompt for cl100k_base ~ 3351\n",
      "**Summary**\n",
      "\n",
      "Embark on an unforgettable 5-day adventure to the vibrant city of Singapore, where you'll immerse yourself in the captivating Little India district and indulge in tantalizing local flavors. Stroll through bustling markets, savor authentic street food, and uncover the rich cultural heritage of this vibrant enclave. Beyond Little India, explore iconic landmarks, experience breathtaking panoramic views, and dive into the diverse culinary scene that Singapore is renowned for.\n",
      "\n",
      "**Journey Highlights**\n",
      "\n",
      "* Explore the vibrant Little India district, a kaleidoscope of colors, aromas, and bustling markets\n",
      "* Savor authentic Indian cuisine and street food on a guided foodie tour\n",
      "* Visit the iconic Merlion and explore the lush Botanic Gardens\n",
      "* Ascend to the top of Marina Bay Sands for breathtaking city views\n",
      "* Indulge in world-class shopping and dining experiences\n",
      "* Your journey takes you to: Kuala Lumpur - Singapore - Little India\n",
      "\n",
      "**Itinerary**\n",
      "\n",
      "**Day 1**\n",
      "\n",
      "* 1000hrs: Arrive at Singapore Changi Airport (SIN)\n",
      "* 1100hrs: Check in at Raffles Hotel (ACCOMODATION ID: 7)\n",
      "* 1400hrs: Guided Little India cultural foodie tour (ACTIVITY ID: 17)\n",
      "* 1900hrs: Dinner at Komala Vilas Restaurant (famous for its vegetarian Indian cuisine)\n",
      "\n",
      "**Day 2**\n",
      "\n",
      "* 0800hrs: Breakfast at Raffles Hotel (ACCOMODATION ID: 7)\n",
      "* 0900hrs: Visit the Merlion and explore the Botanic Gardens (ACTIVITY ID: 16)\n",
      "* 1200hrs: Lunch at the Ginger Garden (for local Singaporean cuisine)\n",
      "* 1400hrs: Visit the National Museum of Singapore\n",
      "* 1800hrs: Shopping and dinner at Orchard Road\n",
      "\n",
      "**Day 3**\n",
      "\n",
      "* 0800hrs: Breakfast at Raffles Hotel (ACCOMODATION ID: 7)\n",
      "* 0900hrs: Ascend to the top of Marina Bay Sands\n",
      "* 1100hrs: Visit the Gardens by the Bay\n",
      "* 1400hrs: Lunch at the Satay by the Bay (for a variety of local street food)\n",
      "* 1800hrs: Enjoy a sunset cruise along the Singapore River\n",
      "\n",
      "**Day 4**\n",
      "\n",
      "* 0800hrs: Breakfast at Raffles Hotel (ACCOMODATION ID: 7)\n",
      "* 0900hrs: Visit the Chinatown district\n",
      "* 1200hrs: Lunch at the Tian Tian Hainanese Chicken Rice (for a Michelin-starred Hainanese chicken rice experience)\n",
      "* 1400hrs: Guided Chinatown cultural foodie tour (ACTIVITY ID: 18)\n",
      "* 1900hrs: Farewell dinner at Lau Pa Sat (a hawker center offering a wide variety of local dishes)\n",
      "\n",
      "**Day 5**\n",
      "\n",
      "* 0800hrs: Breakfast at Raffles Hotel (ACCOMODATION ID: 7)\n",
      "* 1000hrs: Check out of the hotel and depart from Singapore Changi Airport (SIN)\n",
      "\n",
      "**Highlights and Inclusions**\n",
      "\n",
      "* 5-day and 4-night accommodation at Raffles Hotel (ACCOMODATION ID: 7)\n",
      "* Round-trip flights from Kuala Lumpur to Singapore (FLIGHT ID: 8)\n",
      "* Guided Little India cultural foodie tour (ACTIVITY ID: 17)\n",
      "* Visit to the Merlion and Botanic Gardens (ACTIVITY ID: 16)\n",
      "* Ascent to the top of Marina Bay Sands\n",
      "* Shopping and dining experiences\n",
      "* Tiq Travel Insurance (SERVICE ID: 26)\n",
      "\n",
      "**Pricing**\n",
      "\n",
      "* Accommodation: 4 nights x $200/night = $800\n",
      "* Flights: $101 (FLIGHT ID: 8)\n",
      "* Activities: $500 (ACTIVITY ID: 17) + $600 (ACTIVITY ID: 16) = $1100\n",
      "* Services: $40 (SERVICE ID: 26)\n",
      "* Insurance: $40 (SERVICE ID: 26)\n",
      "* Total: **$2040**\n"
     ]
    }
   ],
   "source": [
    "# Ask Traveller to generate a travel package\n",
    "default_query = \"Shaik from Kuala Lumpur wants to go Singapore for 5 days for 2 pax. Budget: $2000. Make one day specifically for Little India. Make leftover days for OTHER casual activities.\"\n",
    "\n",
    "initial_query = input(f\"Enter your initial query (or press Enter to use the default):\\n{default_query}\\n\")\n",
    "\n",
    "# Check if the user entered anything\n",
    "if not initial_query:\n",
    "  initial_query = default_query\n",
    "\n",
    "print(f\"Using initial query: {initial_query}\")\n",
    "\n",
    "\n",
    "convo_package = librarian.Traveller.III_generate_travel_package(initial_query = initial_query,\n",
    "                                                                 topN = 6, \n",
    "                                                                 model_name = \"gemini-pro\",\n",
    "                                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token size of the prompt for cl100k_base ~ 3576\n",
      "**Refined Travel Package**\n",
      "\n",
      "**Summary**\n",
      "\n",
      "Embark on an unforgettable 5-day adventure to the vibrant city of Singapore, where you'll immerse yourself in the captivating Little India district and indulge in tantalizing local flavors. Stroll through bustling markets, savor authentic street food, and uncover the rich cultural heritage of this vibrant enclave. Beyond Little India, explore iconic landmarks, experience breathtaking panoramic views, and dive into the diverse culinary scene that Singapore is renowned for.\n",
      "\n",
      "**Journey Highlights**\n",
      "\n",
      "* Explore the vibrant Little India district, a kaleidoscope of colors, aromas, and bustling markets\n",
      "* Savor authentic Indian cuisine and street food on a guided foodie tour\n",
      "* Visit the iconic Merlion and explore the lush Botanic Gardens\n",
      "* Ascend to the top of Marina Bay Sands for breathtaking city views\n",
      "* Indulge in world-class shopping and dining experiences\n",
      "* Your journey takes you to: Kuala Lumpur - Singapore - Little India\n",
      "\n",
      "**Itinerary**\n",
      "\n",
      "**Day 1**\n",
      "\n",
      "* 1000hrs: Arrive at Singapore Changi Airport (SIN)\n",
      "* 1100hrs: Check in at Marina Bay Sands (ACCOMODATION ID: 8)\n",
      "* 1400hrs: Guided Little India cultural foodie tour (ACTIVITY ID: 17)\n",
      "* 1900hrs: Dinner at Komala Vilas Restaurant (famous for its vegetarian Indian cuisine)\n",
      "\n",
      "**Day 2**\n",
      "\n",
      "* 0800hrs: Breakfast at Marina Bay Sands (ACCOMODATION ID: 8)\n",
      "* 0900hrs: Visit the Merlion and explore the Botanic Gardens (ACTIVITY ID: 16)\n",
      "* 1200hrs: Lunch at the Ginger Garden (for local Singaporean cuisine)\n",
      "* 1400hrs: Visit the National Museum of Singapore\n",
      "* 1800hrs: Shopping and dinner at Orchard Road\n",
      "\n",
      "**Day 3**\n",
      "\n",
      "* 0800hrs: Breakfast at Marina Bay Sands (ACCOMODATION ID: 8)\n",
      "* 0900hrs: Ascend to the top of Marina Bay Sands\n",
      "* 1100hrs: Visit the Gardens by the Bay\n",
      "* 1400hrs: Lunch at the Satay by the Bay (for a variety of local street food)\n",
      "* 1800hrs: Enjoy a sunset cruise along the Singapore River\n",
      "\n",
      "**Day 4**\n",
      "\n",
      "* 0800hrs: Breakfast at Marina Bay Sands (ACCOMODATION ID: 8)\n",
      "* 0900hrs: Visit the Chinatown district\n",
      "* 1200hrs: Lunch at the Tian Tian Hainanese Chicken Rice (for a Michelin-starred Hainanese chicken rice experience)\n",
      "* 1400hrs: Guided Chinatown cultural foodie tour (ACTIVITY ID: 18)\n",
      "* 1900hrs: Farewell dinner at Lau Pa Sat (a hawker center offering a wide variety of local dishes)\n",
      "\n",
      "**Day 5**\n",
      "\n",
      "* 0800hrs: Breakfast at Marina Bay Sands (ACCOMODATION ID: 8)\n",
      "* 1000hrs: Check out of the hotel and depart from Singapore Changi Airport (SIN)\n",
      "\n",
      "**Highlights and Inclusions**\n",
      "\n",
      "* 5-day and 4-night accommodation at Marina Bay Sands (ACCOMODATION ID: 8)\n",
      "* Round-trip flights from Kuala Lumpur to Singapore (FLIGHT ID: 8)\n",
      "* Guided Little India cultural foodie tour (ACTIVITY ID: 17)\n",
      "* Visit to the Merlion and Botanic Gardens (ACTIVITY ID: 16)\n",
      "* Ascent to the top of Marina Bay Sands\n",
      "* Shopping and dining experiences\n",
      "\n",
      "**Pricing**\n",
      "\n",
      "* Accommodation: 4 nights x $341/night = $1364\n",
      "* Flights: $101 (FLIGHT ID: 8)\n",
      "* Activities: $500 (ACTIVITY ID: 17) + $600 (ACTIVITY ID: 16) = $1100\n",
      "* Total: **$2565**\n"
     ]
    }
   ],
   "source": [
    "followup_query = input(\"Enter a followup query to refine the package (or press Enter to skip):\\n\")\n",
    "\n",
    "convo_package = librarian.Traveller.III_generate_travel_package(initial_query = \"\",\n",
    "                                                                followup_query = followup_query,\n",
    "                                                                 topN = 6, \n",
    "                                                                 model_name = \"gemini-pro\",\n",
    "                                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Librarian's Traveller CAPABILITIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) _Retrieval_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Passage': 'CLIENT ID: C139, Client Name: DATO SRI SHAIK AQMAL BIN SHAIK ALAUDDIN, Description: TRAVEL INSURANCE & ACOMMODATION 11 - 18 FEB 2024, Date: 08 Feb 24, Price: 22000.0, Remarks: nan, PREPARED BY: ANIES',\n",
       "  'Similarity Score': 0.5798584591719098},\n",
       " {'Passage': 'CLIENT ID: C018, Client Name: ONE&ONLY DESARU (OODC), Description: Commission to Smart World, Date: 2024-01-03 00:00:00, Price: 2790.6, Remarks: nan, PREPARED BY: EKIN',\n",
       "  'Similarity Score': 0.5793927541501963},\n",
       " {'Passage': \"CLIENT ID: C001, Client Name: DATO' SRI ISMAIL SABRI BIN YAAKOB , Description: SAUDI Trip from 24-30 Dec 2023 For Umrah. Day 1-2: Arrive in Madinah, visit the Prophet's Mosque and historical sites. Day 3-4: Makkah for Tawaf. Day 5: Cave of Hira, Great Mosque. Day 6: Depart, Date: 2023-10-11 00:00:00, Price: 149579.0, Remarks: UMRAH TRIP 24 - 30 DEC 2023, PREPARED BY: HANA\",\n",
       "  'Similarity Score': 0.5754893795861964}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"shaik\"\n",
    "client_recommendations = librarian.Traveller.I_recommend_client(content = prompt,\n",
    "                                                        topN=3,\n",
    "                                                        # task_type = \"retrieval_document\",\n",
    "                                                        task_type = \"retrieval_query\",\n",
    "                                                        )\n",
    "client_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Passage': 'CLIENT ID: C139, Date: 2014-03-24 00:00:00, Location: kuala lumpur, Prompt: dunno, just plan something exciting and cultural with calm vibe around an important AI event of mine on december 24. So i need to be mentally sharp before, and not shagged, Duration: 1 month, Period: 2014-12-12 to 2015-01-12, Budget: 40000, Pax: 2, Client Quirks: doesnt like humid weather and will always prefer somewhere cold, Special Requests: Needs 2 bodyguards at all times',\n",
       "  'Similarity Score': 0.6404644571132381}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Who is the most hardcore client?\"\n",
    "client_recommendations = librarian.Traveller.I_recommend_client_request(content = prompt,\n",
    "                                                        topN=1,\n",
    "                                                        # task_type = \"retrieval_document\",\n",
    "                                                        task_type = \"retrieval_query\",\n",
    "                                                        ) \n",
    "client_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries (assuming you have necessary libraries installed)\n",
    "import numpy as np\n",
    "\n",
    "# Define weights (you can adjust these based on your needs)\n",
    "PROMPT_WEIGHT = 0.8  # Higher weight for user's current interest\n",
    "PROFILE_WEIGHT = 0.2  # Lower weight for user profile\n",
    "\n",
    "def weighted_search(prompt_embedding, user_profile_embedding, recommendations):\n",
    "  \"\"\"\n",
    "  Combines prompt and user profile embedding similarity scores for weighted search.\n",
    "\n",
    "  Args:\n",
    "      prompt_embedding: Embedding representing the user's prompt.\n",
    "      user_profile_embedding: Embedding representing the user's travel profile.\n",
    "      recommendations: List of recommendations (flights, accommodations, services).\n",
    "\n",
    "  Returns:\n",
    "      A list of recommendations sorted by their weighted similarity score.\n",
    "  \"\"\"\n",
    "  # Calculate similarity scores between prompt embedding and each recommendation\n",
    "  prompt_similarities = [np.dot(prompt_embedding, item['embedding']) for item in recommendations]\n",
    "\n",
    "  # Calculate similarity scores between user profile embedding and each recommendation\n",
    "  profile_similarities = [np.dot(user_profile_embedding, item['embedding']) for item in recommendations]\n",
    "\n",
    "  # Combine similarity scores with weights\n",
    "  weighted_scores = [PROMPT_WEIGHT * prompt_sim + PROFILE_WEIGHT * profile_sim \n",
    "                     for prompt_sim, profile_sim in zip(prompt_similarities, profile_similarities)]\n",
    "\n",
    "  # Sort recommendations based on weighted scores (descending order)\n",
    "  sorted_recommendations = sorted(zip(recommendations, weighted_scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "  return [item[0] for item in sorted_recommendations]\n",
    "\n",
    "# Example usage (assuming you have functions to generate prompt and user profile embeddings, \n",
    "# and a list of recommendations with embedding information)\n",
    "prompt_embedding = generate_prompt_embedding(\"I want to go to Singapore\")\n",
    "user_profile_embedding = generate_user_profile_embedding(user_id)\n",
    "recommendations = get_recommendations(\"Singapore\")  # Flights, accommodations, services for Singapore\n",
    "\n",
    "personalized_recommendations = weighted_search(prompt_embedding, user_profile_embedding, recommendations)\n",
    "\n",
    "# Use the personalized_recommendations list for further processing or display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) _Recommend_ : travel logistics (II)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Passage': 'FLIGHT ID: 12, Origin: Singapore, Destination: Kuala Lumpur, Price: from $82 ',\n",
       "  'Similarity Score': 0.7052937218642239},\n",
       " {'Passage': 'FLIGHT ID: 14, Origin: Singapore, Destination: Kuala Lumpur, Price: from $70 ',\n",
       "  'Similarity Score': 0.7012338995802883},\n",
       " {'Passage': 'FLIGHT ID: 13, Origin: Singapore, Destination: Kuala Lumpur, Price: from $153 ',\n",
       "  'Similarity Score': 0.7012112802307542},\n",
       " {'Passage': 'FLIGHT ID: 7, Origin: Kuala Lumpur, Destination: Singapore, Price: from $83',\n",
       "  'Similarity Score': 0.6982578586274387},\n",
       " {'Passage': 'FLIGHT ID: 8, Origin: Kuala Lumpur, Destination: Singapore, Price: from $101',\n",
       "  'Similarity Score': 0.6953344564516624}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = f\"What flights from Singapore to Kuala Lumpur?\"\n",
    "\n",
    "flight_recommendations = librarian.Traveller.I_recommend_flights(content,\n",
    "                                                                  topN = 5, \n",
    "                                                                #  task_type=\"retrieval_document\")\n",
    "                                                                 task_type = \"retrieval_query\")\n",
    "flight_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Passage': 'FLIGHT ID: 12, Origin: Singapore, Destination: Kuala Lumpur, Price: from $82 ',\n",
       "  'Similarity Score': 0.7622100129085936},\n",
       " {'Passage': 'FLIGHT ID: 8, Origin: Kuala Lumpur, Destination: Singapore, Price: from $101',\n",
       "  'Similarity Score': 0.7621598208444731},\n",
       " {'Passage': 'FLIGHT ID: 9, Origin: Kuala Lumpur, Destination: Singapore, Price: from $89',\n",
       "  'Similarity Score': 0.7549945336128664},\n",
       " {'Passage': 'FLIGHT ID: 10, Origin: Kuala Lumpur, Destination: Michigan, Singapore, Price: from $1200',\n",
       "  'Similarity Score': 0.7543854603831508},\n",
       " {'Passage': 'FLIGHT ID: 7, Origin: Kuala Lumpur, Destination: Singapore, Price: from $83',\n",
       "  'Similarity Score': 0.7534204782143469},\n",
       " {'Passage': 'FLIGHT ID: 14, Origin: Singapore, Destination: Kuala Lumpur, Price: from $70 ',\n",
       "  'Similarity Score': 0.7520427625441319},\n",
       " {'Passage': 'FLIGHT ID: 13, Origin: Singapore, Destination: Kuala Lumpur, Price: from $153 ',\n",
       "  'Similarity Score': 0.7500689235748557},\n",
       " {'Passage': 'FLIGHT ID: 23, Origin: Michigan, Singapore, Destination: Kuala Lumpur, Price: from $1200',\n",
       "  'Similarity Score': 0.7464974369278223},\n",
       " {'Passage': 'FLIGHT ID: 17, Origin: Denpasar Bali, Destination: Kuala Lumpur, Price: from $193',\n",
       "  'Similarity Score': 0.7370804883500821},\n",
       " {'Passage': 'FLIGHT ID: 16, Origin: Denpasar Bali, Destination: Kuala Lumpur, Price: from $252',\n",
       "  'Similarity Score': 0.7357880128858286}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = f\"origin Kuala Lumpur, destination Singapore\"\n",
    "\n",
    "flight_recommendations = librarian.Traveller.I_recommend_flights(content,\n",
    "                                                                 topN = 10, \n",
    "                                                                 task_type=\"retrieval_query\")\n",
    "                                                                #  task_type = \"semantic_similarity\")\n",
    "flight_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Client: Shaik\\nClient Request: The client Shaik needs to go Singapore with VIP driver for 6 days, with a focus on chinatown for 1 day. then everything else is free and easy\\nFlights: Singapore airport\\nAccommodations: Singapore\\nActivities: Chinatown tour\\nServices: VIP driver for 6 days'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_query = \"The client Shaik needs to go Singapore with VIP driver for 6 days, with a focus on chinatown for 1 day. then everything else is free and easy\"\n",
    "prompt = f\"\"\"You are a prompt engineer for a travel company. Given the following unstructured request from a client: {initial_query}\n",
    "                        Segment the query into:\n",
    "                        1) Client\n",
    "                        2) Client Request\n",
    "                        3) Flights\n",
    "                        4) Accomodations\n",
    "                        5) Activities\n",
    "                        6) Services, \n",
    "                        So for example, if a client request is \"The client Shaik needs to go Singapore with VIP driver for 5 days, with a focus on arab/malay street\",\n",
    "                        you would segment it into and return:\n",
    "                        'client: Shaik\n",
    "                        client_request: The client Shaik needs to go Singapore with VIP driver for 5 days, with a focus on arab/malay street\n",
    "                        flights: Singapore airport\n",
    "                        accomodations: near arab/malay street, Singapore\n",
    "                        activities: segmented_query:arab/malay street tour\n",
    "                        services: segmented_query:VIP driver for 5 days'\n",
    "                        ALL segments must be returned.\n",
    "                        If any of the segments are not present, then please indicate that the segment is not present and provide fillers. \n",
    "                        \"\"\"\n",
    "response = librarian.Traveller.model_specialist.prompt(prompt)\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Client: Shaik',\n",
       " 'Client Request: The client Shaik needs to go Singapore with VIP driver for 6 days, with a focus on chinatown for 1 day. then everything else is free and easy',\n",
       " 'Flights: Singapore airport',\n",
       " 'Accommodations: Singapore',\n",
       " 'Activities: Chinatown tour',\n",
       " 'Services: VIP driver for 6 days']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the segments\n",
    "segments = response.text.split(\"\\n\")\n",
    "\n",
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('flights:\\n'\n",
      " \"[{'Passage': 'FLIGHT ID: 10, Origin: Kuala Lumpur, Destination: Michigan, \"\n",
      " \"Singapore, Price: from $1200', 'Similarity Score': 0.5314661234074356}, \"\n",
      " \"{'Passage': 'FLIGHT ID: 7, Origin: Kuala Lumpur, Destination: Singapore, \"\n",
      " \"Price: from $83', 'Similarity Score': 0.5302942126398107}, {'Passage': \"\n",
      " \"'FLIGHT ID: 15, Origin: Singapore, Destination: Michigan, Singapore, Price: \"\n",
      " \"from $1300', 'Similarity Score': 0.5281868848282231}]\")\n",
      "('accomodations:\\n'\n",
      " \"[{'Passage': 'ACCOMODATION ID: 7, Name: Raffles hotel, Type: Hotel, \"\n",
      " 'Location: Singapore, Price per night: 200, Description: An iconic **5-star '\n",
      " 'luxury beachfront resort**, exudes timeless elegance. After an extensive '\n",
      " 'restoration, it retains its legendary charm, service, and heritage. Explore '\n",
      " 'newly opened bars, restaurants, and courtyards. The **Long Bar**, home of '\n",
      " 'the famous Singapore Sling, returns fully restored. Located in the heart of '\n",
      " 'the city, close to financial districts, cultural sights, and shopping, '\n",
      " 'Raffles Hotel is a gracious landmark where history meets impeccable service '\n",
      " \"for over 125 years 🌴🌟.\\\\n', 'Similarity Score': 0.6017507898776795}, \"\n",
      " \"{'Passage': 'ACCOMODATION ID: 9, Name: Mandarin Oriental, Type: Hotel, \"\n",
      " 'Location: Singapore, Price per night: 1000, Description: 5 star hotel '\n",
      " \"services, with 5 star breakfast and dinner but no oyster ', 'Similarity \"\n",
      " \"Score': 0.5946050234210385}, {'Passage': 'ACCOMODATION ID: 15, Name: Ghost \"\n",
      " 'Hotel , Type: Colonial Guesthouse, Location: Singapore, Michigan, Price per '\n",
      " 'night: 9090, Description: A stay for not for the faint of heart as the '\n",
      " \"butlers and hotel staff are all in 1800s getup and theme', 'Similarity \"\n",
      " \"Score': 0.5913199062488144}]\")\n",
      "('activities:\\n'\n",
      " \"[{'Passage': 'ACTIVITY ID: 19, Activity: Arab Street cultural foodie tours, \"\n",
      " 'Location: Singapore, Price: $500 per 4 pax, Duration: 5 hours, Category: '\n",
      " \"Tour, Dining, Shopping', 'Similarity Score': 0.682075094609117}, {'Passage': \"\n",
      " \"'ACTIVITY ID: 17, Activity: Little India cultural foodie tours, Location: \"\n",
      " 'Singapore, Price: $500 per 4 pax, Duration: 5 hours, Category: Tour, Dining, '\n",
      " \"Shopping', 'Similarity Score': 0.6323447178364427}, {'Passage': 'ACTIVITY \"\n",
      " 'ID: 18, Activity: ChinaTown cultural foodie tours, Location: Singapore, '\n",
      " \"Price: $500 per 4 pax, Duration: 5 hours, Category: Tour, Dining, Shopping', \"\n",
      " \"'Similarity Score': 0.6101327941170755}]\")\n",
      "('services:\\n'\n",
      " \"[{'Passage': 'SERVICE ID: 30, Services: Sedan driver (Mercedes S Class, 3 \"\n",
      " 'passengers, VIP), Location: Singapore, Price: $800 per 4 pax per day, '\n",
      " \"Category: Driver', 'Similarity Score': 0.6747843775052251}, {'Passage': \"\n",
      " \"'SERVICE ID: 31, Services: MPV driver (Toyota Alphard, 8 passengers, VIP), \"\n",
      " \"Location: Singapore, Price: $1200 per 8 pax per day, Category: Driver', \"\n",
      " \"'Similarity Score': 0.65190925804893}, {'Passage': 'SERVICE ID: 28, \"\n",
      " 'Services: Tourguide + Translator , Location: Singapore, Price: $100 per '\n",
      " \"group per hour, Category: Translator, Guide', 'Similarity Score': \"\n",
      " '0.650376114737962}]')\n"
     ]
    }
   ],
   "source": [
    "# Ask librarian a question regarding one of the specialist databases WITH a chatbot wrapper\n",
    "# input by agent \n",
    "# FUTURE: email thread, entire convo packages - given relevant buckets, eg; dest, duration , budget\n",
    "\n",
    "# TODO LATER: need relevance score to cut out irrelevant data\n",
    "travel_proposal = \"i need to go Singapore with VIP driver for 5 days, with a focus on arab/malay street\"\n",
    "convo_package = librarian.Traveller.II_recommend_travel_logistics(travel_proposal = travel_proposal,\n",
    "                                                                   topN=3,\n",
    "                                                                   chatbot = False, \n",
    "                                                                   chatbot_model_name = \"gemini-pro\")\n",
    "\n",
    "# Highlight: these outputs are from YOUR preferred buckets (your own inventory) but using gemini/openai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) _*Generate*_ : travel proposal (itinerary) from customer request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' The image is of the Sultan Mosque in Singapore. It is a beautiful mosque '\n",
      " 'located in the Kampong Glam district. The mosque is open to visitors from '\n",
      " 'all faiths and is a popular tourist destination.\\n'\n",
      " '\\n'\n",
      " 'Day 1:\\n'\n",
      " '\\n'\n",
      " '* Arrive in Singapore and check into your hotel.\\n'\n",
      " '* Take a walk around the Kampong Glam district and visit the Sultan Mosque.\\n'\n",
      " '* Have dinner at a traditional Malay restaurant.\\n'\n",
      " '\\n'\n",
      " 'Day 2:\\n'\n",
      " '\\n'\n",
      " '* Visit the Gardens by the Bay.\\n'\n",
      " '* Take a boat ride on the Singapore River.\\n'\n",
      " '* Have dinner at a seafood restaurant.\\n'\n",
      " '\\n'\n",
      " 'Day 3:\\n'\n",
      " '\\n'\n",
      " '* Visit the Universal Studios Singapore theme park.\\n'\n",
      " '* Go shopping at the Orchard Road shopping district.\\n'\n",
      " '* Have dinner at a rooftop restaurant with views of the city.\\n'\n",
      " '\\n'\n",
      " 'Free and easy day:\\n'\n",
      " '\\n'\n",
      " '* Visit the Singapore Zoo.\\n'\n",
      " '* Go to the Singapore Botanic Gardens.\\n'\n",
      " '* Take a walk through the Chinatown district.\\n'\n",
      " '* Have dinner at a Peranakan restaurant.')\n"
     ]
    }
   ],
   "source": [
    "# Ask librarian a question regarding one of the specialist databases\n",
    "travel_proposal_request = \"i need to go Singapore for a week, like in this image. Please plan 3 day trip for this country (with 1 day specifically for the location in the image), then a free and easy day where you can fill it up with as much activities as possible from the \"\n",
    "convo_package = librarian.Traveller.II_generate_travel_proposal(input_prompt = travel_proposal_request,\n",
    "                                                                model_name = \"gemini-pro\",\n",
    "                                                                image_path = \"./database/travel/sometiktokss.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: flawed or hallucinated responses have to be stored and set as bad example for future response \n",
    "# eg; this package is hallucinating dicsount vouchers at orchard road - this is a bad example, and should be flagged as such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SELECT SPECIALIST DATABASE\n",
    "# librarian.select_specialist(specialist = \"muslim\", specialist_LLM_model = \"GEMINI\")\n",
    "# librarian.Muslim.load_data_model(reembed = False,\n",
    "#                                     data_model_keys = {\"Quran\":\"SURAH ID\",\n",
    "#                                                         \"Hadith\":\"HADITH ID\",\n",
    "#                                                         \"Tafsir\":\"TAFSIR ID\",\n",
    "#                                                         }\n",
    "#                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Notes:\n",
    "at 35:34\n",
    "text Splitting has to be done by relevance ->embeddings_search --> topN -> chain back to LLM --> talk to AI (+relevance)\n",
    "\n",
    "at 41:30\n",
    "Okay nice, he is explanining RAG nicely :\n",
    "my thoughts at that timestamp:\n",
    "TECH LEVELS:\n",
    "1) image + text  -> text \n",
    "    - No context: LLM only\n",
    "    - eg; LLM(\"Hey AI, give me information on X\")\n",
    "2) image + text -> text  \n",
    "    - Basic Contextualist: Context sample + LLM\n",
    "    - eg; LLM(\"Hey AI, give me information on X, given (Context sample)\")\n",
    "3) image + text -> text \n",
    "    - Big Contextualist: Context Population + Recommendation engine + LLM\n",
    "    - eg; RAG(\"Hey AI, give me information on X\", Librarian(topN, X, Context Population))\n",
    "\n",
    "at44:31, yes nice explanation of dimensionality reduction\n",
    "\n",
    "\n",
    "at 46:55: have to classify all avialable LLMs by\n",
    "matching capabilities, (based on Baijun's picture for example, CLAUDE has best reasoning --> does this imply better model embeddings?)\n",
    "COST (token, contextualising cost)\n",
    "\n",
    "\n",
    "at 51:38:\n",
    "macthing parameters (similiarity)\n",
    "cosine most popular, but could there be other techiques could have better edge at certain data?? (to investigate)\n",
    "\n",
    "\n",
    "\n",
    "at 53:50:\n",
    "VECTOR STORE\n",
    "db for embeddings/vectors\n",
    "to store all documents, auto gen emebddings, store auto\n",
    "!!! Vector stores are optimised to do similiarity really WELL\n",
    "sure anot, what optimisation, should we built everything inhouse to not be dependant. all this just funnels to get to pay for pinecone only. but yea gotta check cost-benefit here\n",
    "i've already make everything up till 56mins from scratch already, we already have.\n",
    "just maybe vector stores. must compare pricing and efficacy of available vector stores\n",
    "\n",
    "\n",
    "at 59:04:\n",
    "VECTOR STORE features\n",
    "vector_store.as_retriever\n",
    "connects directly to vector_store to get topN\n",
    "langchain is a wrapper for LLMs. but gemini already has this feature built in.\n",
    "scope: we aggregate all this LLM services. but remain portable and Microservices oriented as any one of them cld be bought over by corps (no new updates), etc\n",
    "\n",
    "61:09 onwards is dry pinecone stuff\n",
    "but yea could have features must replicate/generalise\n",
    "\n",
    "at 1:01:33\n",
    "LangChain codebase/structure highlights\n",
    "prompts themselves are CLASSES, which are modularly attached to RETRIEVER_CLASS\n",
    "whereas mine is functions only. Need persistence!!\n",
    "\n",
    "at1:04:20:\n",
    "langchain codebase highlights\n",
    "vector_stores are wrapped in highly functionable classes\n",
    "whereas mine is all objects\n",
    "\n",
    "\n",
    "at 1:06:46:\n",
    "Langchain UX experience and ease of \"chaining\":\n",
    "(context + prompt + model + parser ) + prompt\n",
    "so its an infinite way to arrange this.\n",
    "this is basically modelling conversations with a librarian, and then to self, then writing to paper, then retalk again to librarian, then write again.\n",
    "\n",
    "at1:09:30\n",
    "!!! We need to have an AI DATA MODEL map\n",
    "where we map out the AI conversations with respect to mapping to different specialist databases, human prompts, - its a conversation web modelling\n",
    "\n",
    "\n",
    "at 1:12:12\n",
    "wrapup:\n",
    "nice video on RAG, will have to use whisper for youtube\n",
    "FUTURE: can even consider other data inputs\n",
    " images (we have)\n",
    "sound + video frames\n",
    "UI: how? screenshot? video download? links?\n",
    "AI DATA MODEL:\n",
    "Process flow of conversation with Librarian and User-\n",
    "prompt engineering to meet expected outputs (QA)\n",
    "How to model conversations effectively (with constraints on COST/SPEED OF QUERY)\n",
    "optimisation? graph theory? or even use a Graph convolutional network on top of all the web to optimise conversation path and prompt engineering?\n",
    "this is athena i think and all those other company internal AI for boosting efficiency\n",
    "\n",
    "\n",
    "Post video: \n",
    "IDEA:\n",
    "lol if a RAG can do exactly my Youtube Keynotes taking here with analyses,\n",
    "analysts will be hyperturbocharged liao\n",
    "but yea depends on specialist database. so ultimately needs an SME of SME, or a specialist of the specialist database to curate this database. but yea can go even higher dimensions, reach all fields, to reach true GAI\n",
    "Which is what LLM+search engines (bing copilot) aspire to do? try to be the new google across all domains, with references,\n",
    "but not for just for information querying but for user experience, like Samsung AI\n",
    "which is making user interface more seamless with AI augmentations.\n",
    "\n",
    "so UI UX side, we should focus on what samsung is doing:\n",
    "these are the AI funnels:\n",
    "\n",
    "\"You\n",
    "galaxy ai features\n",
    "Copilot\n",
    "Certainly! Here are some of the features of Galaxy AI:\n",
    "\n",
    "Circle to Search: This feature allows you to draw a circle around any object in an image, and Galaxy AI will search for relevant information related to that object.\n",
    "Browsing Assist: Galaxy AI can assist with web browsing by summarizing articles, providing relevant links, and answering questions based on web content.\n",
    "Transcript Assist: When you upload an audio or video file, Galaxy AI can transcribe the spoken content and provide a text-based summary.\n",
    "Photo Assist: Upload an image, and Galaxy AI can describe its contents, identify objects, and provide context.\n",
    "Generative Edit: Galaxy AI can help generate creative content, such as poems, stories, code, and more.\n",
    "Call Assist/Live Translate: During phone calls, Galaxy AI can provide real-time translation or assist with conversation summaries.\n",
    "Chat Assist: Engage in text-based conversations with Galaxy AI, which can respond contextually and provide helpful information.\n",
    "Note Assist: Galaxy AI can summarize notes, generate outlines, and assist with organizing information.\"\n",
    "\n",
    "then formulate all of the thinking (and whatever lacking) behind my chats above into a RAG - then we have an AI business analyst LOL\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keynotes_log = \"\"\"\n",
    "Key Notes:\n",
    "at 35:34\n",
    "text Splitting has to be done by relevance ->embeddings_search --> topN -> chain back to LLM --> talk to AI (+relevance)\n",
    "\n",
    "at 41:30\n",
    "Okay nice, he is explanining RAG nicely :\n",
    "my thoughts at that timestamp:\n",
    "TECH LEVELS:\n",
    "1) image + text  -> text \n",
    "    - No context: LLM only\n",
    "    - eg; LLM(\"Hey AI, give me information on X\")\n",
    "2) image + text -> text  \n",
    "    - Basic Contextualist: Context sample + LLM\n",
    "    - eg; LLM(\"Hey AI, give me information on X, given (Context sample)\")\n",
    "3) image + text -> text \n",
    "    - Big Contextualist: Context Population + Recommendation engine + LLM\n",
    "    - eg; RAG(\"Hey AI, give me information on X\", Librarian(topN, X, Context Population))\n",
    "\n",
    "at44:31, yes nice explanation of dimensionality reduction\n",
    "\n",
    "\n",
    "at 46:55: have to classify all avialable LLMs by\n",
    "matching capabilities, (based on Baijun's picture for example, CLAUDE has best reasoning --> does this imply better model embeddings?)\n",
    "COST (token, contextualising cost)\n",
    "\n",
    "\n",
    "at 51:38:\n",
    "macthing parameters (similiarity)\n",
    "cosine most popular, but could there be other techiques could have better edge at certain data?? (to investigate)\n",
    "\n",
    "\n",
    "\n",
    "at 53:50:\n",
    "VECTOR STORE\n",
    "db for embeddings/vectors\n",
    "to store all documents, auto gen emebddings, store auto\n",
    "!!! Vector stores are optimised to do similiarity really WELL\n",
    "sure anot, what optimisation, should we built everything inhouse to not be dependant. all this just funnels to get to pay for pinecone only. but yea gotta check cost-benefit here\n",
    "i've already make everything up till 56mins from scratch already, we already have.\n",
    "just maybe vector stores. must compare pricing and efficacy of available vector stores\n",
    "\n",
    "\n",
    "at 59:04:\n",
    "VECTOR STORE features\n",
    "vector_store.as_retriever\n",
    "connects directly to vector_store to get topN\n",
    "langchain is a wrapper for LLMs. but gemini already has this feature built in.\n",
    "scope: we aggregate all this LLM services. but remain portable and Microservices oriented as any one of them cld be bought over by corps (no new updates), etc\n",
    "\n",
    "61:09 onwards is dry pinecone stuff\n",
    "but yea could have features must replicate/generalise\n",
    "\n",
    "at 1:01:33\n",
    "LangChain codebase/structure highlights\n",
    "prompts themselves are CLASSES, which are modularly attached to RETRIEVER_CLASS\n",
    "whereas mine is functions only. Need persistence!!\n",
    "\n",
    "at1:04:20:\n",
    "langchain codebase highlights\n",
    "vector_stores are wrapped in highly functionable classes\n",
    "whereas mine is all objects\n",
    "\n",
    "\n",
    "at 1:06:46:\n",
    "Langchain UX experience and ease of \"chaining\":\n",
    "(context + prompt + model + parser ) + prompt\n",
    "so its an infinite way to arrange this.\n",
    "this is basically modelling conversations with a librarian, and then to self, then writing to paper, then retalk again to librarian, then write again.\n",
    "\n",
    "at1:09:30\n",
    "!!! We need to have an AI DATA MODEL map\n",
    "where we map out the AI conversations with respect to mapping to different specialist databases, human prompts, - its a conversation web modelling\n",
    "\n",
    "\n",
    "at 1:12:12\n",
    "wrapup:\n",
    "nice video on RAG, will have to use whisper for youtube\n",
    "FUTURE: can even consider other data inputs\n",
    " images (we have)\n",
    "sound + video frames\n",
    "UI: how? screenshot? video download? links?\n",
    "AI DATA MODEL:\n",
    "Process flow of conversation with Librarian and User-\n",
    "prompt engineering to meet expected outputs (QA)\n",
    "How to model conversations effectively (with constraints on COST/SPEED OF QUERY)\n",
    "optimisation? graph theory? or even use a Graph convolutional network on top of all the web to optimise conversation path and prompt engineering?\n",
    "this is athena i think and all those other company internal AI for boosting efficiency\n",
    "\n",
    "\n",
    "Post video: \n",
    "IDEA:\n",
    "lol if a RAG can do exactly my Youtube Keynotes taking here with analyses,\n",
    "analysts will be hyperturbocharged liao\n",
    "but yea depends on specialist database. so ultimately needs an SME of SME, or a specialist of the specialist database to curate this database. but yea can go even higher dimensions, reach all fields, to reach true GAI\n",
    "Which is what LLM+search engines (bing copilot) aspire to do? try to be the new google across all domains, with references,\n",
    "but not for just for information querying but for user experience, like Samsung AI\n",
    "which is making user interface more seamless with AI augmentations.\n",
    "\n",
    "so UI UX side, we should focus on what samsung is doing:\n",
    "these are the AI funnels:\n",
    "\n",
    "\"You\n",
    "galaxy ai features\n",
    "Copilot\n",
    "Certainly! Here are some of the features of Galaxy AI:\n",
    "\n",
    "Circle to Search: This feature allows you to draw a circle around any object in an image, and Galaxy AI will search for relevant information related to that object.\n",
    "Browsing Assist: Galaxy AI can assist with web browsing by summarizing articles, providing relevant links, and answering questions based on web content.\n",
    "Transcript Assist: When you upload an audio or video file, Galaxy AI can transcribe the spoken content and provide a text-based summary.\n",
    "Photo Assist: Upload an image, and Galaxy AI can describe its contents, identify objects, and provide context.\n",
    "Generative Edit: Galaxy AI can help generate creative content, such as poems, stories, code, and more.\n",
    "Call Assist/Live Translate: During phone calls, Galaxy AI can provide real-time translation or assist with conversation summaries.\n",
    "Chat Assist: Engage in text-based conversations with Galaxy AI, which can respond contextually and provide helpful information.\n",
    "Note Assist: Galaxy AI can summarize notes, generate outlines, and assist with organizing information.\"\n",
    "\n",
    "then formulate all of the thinking (and whatever lacking) behind my chats above into a RAG - then we have an AI business analyst LOL\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KnowledgeBase - Financial Data Time Series\n",
    "LLM image analysis --> analyse_travel_destination --> Concierge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) PROMPT input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = \"2024-03-04\"\n",
    "prompt_0 = f\"\"\"\n",
    "What is the current price of Bitcoin for today ({date})? What is the latest financial news, outlook on the crypto market, \n",
    "and also contrast with the traditional stock market and money market.\n",
    "\"\"\"\n",
    "from settings import GEMINI_API_KEY\n",
    "from llm_handler.GHandler import GHandler\n",
    "\n",
    "g_handler = GHandler(GEMINI_API_KEY)\n",
    "\n",
    "response = g_handler.prompt(prompt_0)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Image input: Multimodal LLM image analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path = \"./database/quant/btcusdt_1d_IST.png\"\n",
    "image_path = \"./database/quant/buddy_chinese.png\"\n",
    "\n",
    "prompt_1 = f\"\"\"\n",
    "            you are an expert AI generated image analyst- in a AI ethics and misuse department.\n",
    "            You are given images and asked to analyse them if it is AI generated or not.\n",
    "            And give your reasonings.\n",
    "            \"\"\"\n",
    "prompt_2 = f\"\"\"If the image is AI generated, provide a confidence score from 0 to 100,\n",
    "            and recreate the prompt that generated the image. \n",
    "            If the image is not AI generated, then craft a single paragraph, descriptive prompt that could result in a similar image.\n",
    "\"\"\"\n",
    "# prompt_2v = f\"\"\"If the image is AI generated, provide a confidence score from 0 to 100,\n",
    "# \"The expert AI generated image analyst response to the prior prompt ({prompt_1}) is: \n",
    "# <trader's RESPONSE>\".\n",
    "# \"My own thoughts on his response is: \n",
    "# <vibe_checker's RESPONSE>\".\n",
    "# \"Confidence: <YOUR_SCORE>\".\n",
    "# \"\"\"\n",
    "from IPython.display import Image, display\n",
    "display(Image(filename=image_path))\n",
    "from pprint import pprint\n",
    "from settings import GEMINI_API_KEY\n",
    "from llm_handler.GHandler import GHandler\n",
    "\n",
    "g_handler = GHandler(GEMINI_API_KEY)\n",
    "\n",
    "g_response = g_handler.prompt_image(model_name = \"gemini-pro-vision\",\n",
    "                                  image_path = image_path,\n",
    "                                  prompt_1 = prompt_1,\n",
    "                                  prompt_2 = prompt_2,\n",
    "                                  generation_config = {\n",
    "                                                        \"temperature\": 0.9,\n",
    "                                                        \"top_p\": 0.95,\n",
    "                                                        \"top_k\": 40,\n",
    "                                                        \"max_output_tokens\": 1024,\n",
    "                                                        },\n",
    "                                block_threshold = \"BLOCK_NONE\"\n",
    "                                        )\n",
    "# print this in a nicer format and not stretched beyond the screen\n",
    "pprint(g_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Generate an image with the following description: \n",
    " \"The photograph is of a gray tabby cat being held by a person. The cat's eyes \"\n",
    " 'are partially closed and it looks relaxed. The photograph is taken from a '\n",
    " 'close-up angle and the background is out of focus.\\n'\n",
    " '\\n'\n",
    " 'To take a similar photograph, you would need a camera and a cat. You would '\n",
    " 'need to get close to the cat and take the photograph when it is relaxed. You '\n",
    " 'could also use a telephoto lens to get a closer shot.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snippet you provided attempts to utilize the Gemini-Pro-Vision model for image analysis in the context of a financial time series chart. However, there are several limitations and concerns to consider:\n",
    "\n",
    "**Limitations:**\n",
    "\n",
    "1. **Model capabilities:** While Gemini-Pro-Vision is trained on a massive dataset of text and code, it isn't specifically designed for analyzing financial charts. Its ability to interpret the image and provide the specific descriptions, diagnoses, predictions, and prescriptions you require might be limited.\n",
    "\n",
    "2. **Data complexity:** Financial charts contain complex information encoded in lines, colors, and patterns. Capturing this information and translating it into accurate financial insights requires specialized training data and models.\n",
    "\n",
    "**Concerns:**\n",
    "\n",
    "1. **Over-reliance on LLM:** The code fully relies on the LLM's interpretation of the image, leaving no room for human expertise or domain knowledge. This can lead to inaccurate or misleading financial insights.\n",
    "\n",
    "2. **Ethical considerations:** Using an LLM for financial predictions without proper validation and transparency can be risky. It's essential to be clear about the limitations of the system and emphasize that its output should not be solely relied upon for investment decisions.\n",
    "\n",
    "3. **Potential misuse:** This approach might encourage users to interpret the LLM's output as financial advice, even though it might lack the necessary accuracy and context.\n",
    "\n",
    "**Alternative Approach:**\n",
    "\n",
    "Instead of relying solely on an LLM, consider a more **hybrid approach**:\n",
    "\n",
    "1. **Human Analysis:** Involve a human financial analyst to analyze the chart and provide their expertise. This can help ensure the accuracy and reliability of the initial assessment.\n",
    "\n",
    "2. **LLM Support:** Use the LLM to **complement the human analysis** by:\n",
    "    * Summarizing relevant financial news or historical data related to the instrument.\n",
    "    * Providing alternative perspectives or highlighting potential risks.\n",
    "    * Generating different creative writing formats (e.g., a news article about the market situation) based on the analyst's insights.\n",
    "\n",
    "This approach leverages the strengths of both humans and LLMs, potentially leading to more robust and reliable insights while mitigating ethical concerns.\n",
    "\n",
    "It's crucial to remember that LLMs are still under development, and their capabilities in specialized domains like finance are evolving. While they can be valuable tools, exercising caution and combining them with human expertise remains essential, especially when dealing with financial decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Inventory Recommendation Engine\n",
    "\n",
    "\n",
    "i) Embed database\n",
    "\n",
    "ii) embed user_travel_LLM_response above\n",
    "\n",
    "iii) AI recommendation engine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Embed -> Recommend Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = \"./database/travel/Data Model for Travel.xlsx\"\n",
    "sheet_name = \"Day Trip\"\n",
    "\n",
    "from settings import GEMINI_API_KEY\n",
    "from llm_handler import GHandler\n",
    "import importlib\n",
    "importlib.reload(GHandler)\n",
    "from llm_handler.GHandler import GHandler\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "day_trips_df = pd.read_excel(db_path, sheet_name=sheet_name)\n",
    "# need to embed the day_trips_df\n",
    "day_trips_df[\"Text\"] = day_trips_df.apply(lambda row: f\"Activity: {row['Activity']}, Location: {row['Location']}, Category: {row['Category']} Price: {row['Price']}\", axis=1)\n",
    "\n",
    "\n",
    "g_handler = GHandler(GEMINI_API_KEY)\n",
    "df_embedded = g_handler.embed_df(day_trips_df,\n",
    "                                 title = \"Activity\", \n",
    "                                 text = \"Text\",\n",
    "                                 model=\"models/embedding-001\")\n",
    "daytrip_recommendation = g_handler.find_best_passage(g_response.text, df_embedded)\n",
    "print(daytrip_recommendation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Cascade Recommendation Engine\n",
    "\n",
    "Given the user's primary match, the recommendation engine will look up secondary and tertiary recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings for the hotels and flights\n",
    "flights_hotels_df = pd.read_excel(r'./database/travel/Data Model for Travel.xlsx', sheet_name=\"Hotels\")\n",
    "# drop where type == Nan\n",
    "flights_hotels_df = flights_hotels_df.dropna(subset=[\"Type\"])\n",
    "flights_hotels_df[\"Text\"] = flights_hotels_df.apply(lambda row: f\"Name: {row['Name']}, Type: {row['Type']}, Location: {row['Location']}, Price: {row['Price']}, Description: {row['Description']}\", axis=1)\n",
    "\n",
    "\n",
    "g_handler = GHandler(GEMINI_API_KEY)\n",
    "flights_hotels_df = g_handler.embed_df(flights_hotels_df,\n",
    "                                 title = \"Name\", \n",
    "                                 text = \"Text\",\n",
    "                                 model=\"models/embedding-001\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Convo_2 = f\"\"\"I have an inventory for a {daytrip_recommendation}. I can recommend you a more luxurious based on the location of the activity.\"\"\"\n",
    "hotel_recommendation = g_handler.find_best_passage(Convo_2, flights_hotels_df)\n",
    "print(hotel_recommendation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Convo_3 = f\"\"\"I have an inventory for a {daytrip_recommendation}. I can recommend you the longest flight based on the location of the activity.\"\"\"\n",
    "flight_recommendation = g_handler.find_best_passage(Convo_3, flights_hotels_df)\n",
    "print(flight_recommendation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_hotels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper that inserts\n",
    "# daytrip + hotel + flight into a 3 day 2 night itenerary\n",
    "# so first day fill with casual eating and sightseeing, then 2nd day is the daytrip focus, and 3rd day is the return flight\n",
    "# LLM has to be smart enough to infer duration of daytrip (hiking mt rinjani is 2 days, so it should be 2 days 1 night)\n",
    "\n",
    "# Eg: himalayas\n",
    "# has to account for weather, seasons, and other factors that might affect the trip duration. Or postpone trip under more optimal factors\n",
    "# TESTCASE: NO inventory for customer request\n",
    "# TESTCASE: transport types (ferries, etc)\n",
    "\n",
    "# look at all factor buckets that involves inventory \n",
    "# Buckets to quantify the inventory\n",
    "# main factor is affiliation, services (driver, villa-cook, guide, translator), then location, then price, then type, then rating, then availability, then duration, then weather, then season, then other factors)\n",
    "# if not affiliated then shouldnt be recommended \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top n recommendations (pro consumer vs pro business)\n",
    "\n",
    "# need to see if they have existing monetisation strategy for their travel packages\n",
    "# recommmendations should be tailored to their monetisation strategy\n",
    "# (eg: if they have a partnership with a hotel, then recommend that hotel)\n",
    "\n",
    "\n",
    "# main objective: recommendation engine \n",
    "# warning: no buckets for existing monetisation strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daytrip_recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UX_prompt = f\"\"\"\n",
    "Generate a travel package for the given trip_recommendation:\n",
    "{daytrip_recommendation}\n",
    "\n",
    "This trip_recommendation comes with the following hotel recommendation:\n",
    "{hotel_recommendation}\n",
    "\n",
    "This trip_recommendation comes with the following flight recommendation:\n",
    "{flight_recommendation}\n",
    "\n",
    "The package should include the following sections:\n",
    "\n",
    "\"Summary\"\n",
    "introductory and summary of the trip in one paragraph.\n",
    "The summary should describe in vivid detail, the main attractions, activities, and experiences that the travelers can enjoy in the trip_recommendation. \n",
    "\n",
    "\"Journey Highlights\"\n",
    "A list of the main features and most exciting aspects of the package.\n",
    "the highlights must end off with a bold line: \"Your journey takes you to: x - y - z\"\n",
    "\n",
    "\"Itinerary & Map\" \n",
    "This section is an itenerary list that shows the day-by-day plan of the trip, that is also accompanied by a map.\n",
    "\n",
    "The itinerary should include the name, location, and description of each place or activity that the travelers will visit or do each day. \n",
    "The itinerary should also indicate the approximate duration and transportation mode for each item.\n",
    "\n",
    "A highlights and inclusions section that lists the main features and benefits of the package. \n",
    "The section should mention what is included in the price, such as flights, accommodation, meals, guides, entrance fees, etc. \n",
    "The section should also mention any special offers or discounts that are available for the package.\n",
    "A dates and pricing section that shows the available dates and prices for the package. \n",
    "The section should indicate the departure and return dates, the number of travelers, the total cost, and the payment options for the package. \n",
    "The section should also provide a link or contact information for booking or inquiring about the package.\n",
    "\n",
    "All information derived here should be based on the recommendations from the previous steps and MUST not be fabricated.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from settings import GEMINI_API_KEY\n",
    "from llm_handler.GHandler import GHandler\n",
    "\n",
    "g_handler = GHandler(GEMINI_API_KEY)\n",
    "\n",
    "response_UX = g_handler.prompt(UX_prompt)\n",
    "print(response_UX.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format mimic from image of travel website package page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./database/travel/lux_example.jpg\"\n",
    "prompt_1 = f\"\"\"Reproduce the format of this travel package given a different destination: \n",
    "Generate a travel package for the given trip_recommendation:\n",
    "{daytrip_recommendation}\n",
    "\n",
    "This trip_recommendation comes with the following hotel recommendation:\n",
    "{hotel_recommendation}\n",
    "\n",
    "This trip_recommendation comes with the following flight recommendation:\n",
    "{flight_recommendation}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from IPython.display import Image, display\n",
    "# display(Image(filename=image_path))\n",
    "\n",
    "from settings import GEMINI_API_KEY\n",
    "from llm_handler.GHandler import GHandler\n",
    "\n",
    "g_handler = GHandler(GEMINI_API_KEY)\n",
    "\n",
    "g_response = g_handler.prompt_image(model_name = \"gemini-pro-vision\",\n",
    "                                  image_path = image_path,\n",
    "                                  prompt_1 = prompt_1,\n",
    "                                  prompt_2 = None)\n",
    "print(g_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e) Full Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./database/travel/me-at-kelingking-beach-nusa-penida-bali-inonesia-laugh-traveleat.jpg\"\n",
    "prompt_1 = \"Tell me the location where this photo is taken from?\"\n",
    "prompt_2 = \"Based on the response, recommend a full day trip travel itinerary\"\n",
    "from IPython.display import Image, display\n",
    "print(\"(a) Image Analyses\")\n",
    "display(Image(filename=image_path))\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from settings import GEMINI_API_KEY\n",
    "from llm_handler.GHandler import GHandler\n",
    "\n",
    "g_handler = GHandler(GEMINI_API_KEY)\n",
    "\n",
    "g_response = g_handler.prompt_image(model_name = \"gemini-pro-vision\",\n",
    "                                  image_path = image_path,\n",
    "                                  prompt_1 = prompt_1,\n",
    "                                  prompt_2 = prompt_2)\n",
    "# print(g_response.text)\n",
    "print(\"(b) Image Analyses Complete\")\n",
    "\n",
    "db_path = \"./database/travel/Data Model for Travel.xlsx\"\n",
    "sheet_name = \"Day Trip\"\n",
    "\n",
    "def get_day_trip_recommendation(g_response, db_path, sheet_name):\n",
    "    day_trips_df = pd.read_excel(db_path, sheet_name=sheet_name)\n",
    "    # need to embed the day_trips_df\n",
    "    day_trips_df[\"Text\"] = day_trips_df.apply(lambda row: f\"Activity: {row['Activity']}, Location: {row['Location']}, Category: {row['Category']} Price: {row['Price']}\", axis=1)\n",
    "\n",
    "\n",
    "    g_handler = GHandler(GEMINI_API_KEY)\n",
    "    df_embedded = g_handler.embed_df(day_trips_df,\n",
    "                                    title = \"Activity\", \n",
    "                                    text = \"Text\",\n",
    "                                    model=\"models/embedding-001\")\n",
    "    daytrip_recommendation = g_handler.find_best_passage(g_response.text, df_embedded)\n",
    "    return daytrip_recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = \"./database/travel/Data Model for Travel.xlsx\"\n",
    "sheet_name = \"Day Trip\"\n",
    "\n",
    "from settings import GEMINI_API_KEY\n",
    "from llm_handler import GHandler\n",
    "import importlib\n",
    "importlib.reload(GHandler)\n",
    "from llm_handler.GHandler import GHandler\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "day_trips_df = pd.read_excel(db_path, sheet_name=sheet_name)\n",
    "# need to embed the day_trips_df\n",
    "day_trips_df[\"Text\"] = day_trips_df.apply(lambda row: f\"Activity: {row['Activity']}, Location: {row['Location']}, Category: {row['Category']} Price: {row['Price']}\", axis=1)\n",
    "\n",
    "\n",
    "g_handler = GHandler(GEMINI_API_KEY)\n",
    "df_embedded = g_handler.embed_df(day_trips_df,\n",
    "                                 title = \"Activity\", \n",
    "                                 text = \"Text\",\n",
    "                                 model=\"models/embedding-001\")\n",
    "daytrip_recommendation = g_handler.find_best_passage(g_response.text, df_embedded)\n",
    "print(daytrip_recommendation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Talk to your Fitra AI \n",
    "\n",
    "So imagine you are walking back home, from work, on your phone, \n",
    "Then you see a website with some inspiring duas, and you want to analyse and \n",
    "understand the meaning of the duas, and you want to know the meaning of the duas,\n",
    "and find contextually similiar duas or information. \n",
    "eg;\n",
    "- \"Rabbana atina fid-dunya hasanatan wa fil 'akhirati hasanatan waqina 'adhaban-nar\"\n",
    "- \"Our Lord, give us in this world [that which is] good and in the Hereafter [that which is] good and protect us from the punishment of the Fire.\"\n",
    "- then you want to find similar duas, or background information about this dua like its origins, hadith chains, and all that \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TECH LEVELS:\n",
    "1) image + text  -> text \n",
    "    - No context: LLM only\n",
    "    - eg; LLM(\"Hey AI, give me information on X\")\n",
    "2) image + text -> text  \n",
    "    - Basic Contextualist: Context sample + LLM\n",
    "    - eg; LLM(\"Hey AI, give me information on X, given (Context sample)\")\n",
    "3) image + text -> text \n",
    "    - Big Contextualist: Context Population + Recommendation engine + LLM\n",
    "    - eg; RAG(\"Hey AI, give me information on X\", Librarian(topN, X, Context Population))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from specialists.muslim import Muslim \n",
    "muslim = Muslim()\n",
    "muslim.load_data_model(reembed = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = muslim.tables[\"Sunan al Tirmidhi\"].iloc[1,1]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= muslim.model_specialist.embed_text(title= \"hadith\", text= text, model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from llm_handler.GHandler import GHandler\n",
    "from settings import GEMINI_API_KEY\n",
    "\n",
    "g_handler = GHandler(GEMINI_API_KEY)\n",
    "\n",
    "db_path = \"./database/muslim/Sunan al Tirmidhi.csv\"\n",
    "df = pd.read_csv(db_path)\n",
    "df.iloc[0]\n",
    "\n",
    "#  translate df.iloc[0] from arabic to english\n",
    "response = g_handler.prompt(f\"Please translate the following from arabic to english: It is from a hadith: {df.iloc[0,0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tech tier I: Basic Contextualist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path = \"./database/quant/btcusdt_1d_IST.png\"\n",
    "image_path = \"./database/Fitra AI/dua_1.png\"\n",
    "\n",
    "prompt_1 = f\"\"\"\n",
    "            You are a curator and specialist of all knowledge regarding Islam- \n",
    "            in a AI ethics and misuse department.\n",
    "            You are given images and asked to analyse them for their Islamic content and also level of AI influence.\n",
    "            So look firstly, for Islamic data authenticity then after that, if there are any AI generated content,\n",
    "            especially in meanings or translations, give your reasonings.\n",
    "            \"\"\"\n",
    "prompt_2 = f\"\"\"\n",
    "            If the image is not AI generated and is authentic Islamic content, \n",
    "            then suggest a list of relevant topics to the Islamic content in this image,\n",
    "            such as its origins, hadith sources, Quran sources, and other relevant Islamic topics.\n",
    "\"\"\"\n",
    "# prompt_2v = f\"\"\"If the image is AI generated, provide a confidence score from 0 to 100,\n",
    "# \"The expert AI generated image analyst response to the prior prompt ({prompt_1}) is: \n",
    "# <trader's RESPONSE>\".\n",
    "# \"My own thoughts on his response is: \n",
    "# <vibe_checker's RESPONSE>\".\n",
    "# \"Confidence: <YOUR_SCORE>\".\n",
    "# \"\"\"\n",
    "from IPython.display import Image, display\n",
    "display(Image(filename=image_path))\n",
    "from pprint import pprint\n",
    "from settings import GEMINI_API_KEY\n",
    "from llm_handler.GHandler import GHandler\n",
    "\n",
    "g_handler = GHandler(GEMINI_API_KEY,\n",
    "                     generation_config = {\"temperature\": 0.9,\n",
    "                                      \"top_p\": 0.95,\n",
    "                                      \"top_k\": 40,\n",
    "                                      \"max_output_tokens\": 1024,\n",
    "                                      },\n",
    "                     block_threshold=\"BLOCK_NONE\",\n",
    "                    )\n",
    "\n",
    "g_response = g_handler.prompt_image(model_name = \"gemini-pro-vision\",\n",
    "                                  image_path = image_path,\n",
    "                                  prompt_1 = prompt_1,\n",
    "                                  prompt_2 = prompt_2,)\n",
    "# print this in a nicer format and not stretched beyond the screen\n",
    "pprint(g_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tech tier II: Small Contextualist\n",
    "\n",
    "\n",
    "i) Embed database\n",
    "\n",
    "ii) embed user_travel_LLM_response above\n",
    "\n",
    "iii) AI recommendation engine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Embed -> Recommend Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = \"./database/travel/SWTT_ Master Database.xlsx\"\n",
    "sheet_name = \"CUSTOMERS\"\n",
    "\n",
    "from settings import GEMINI_API_KEY\n",
    "from llm_handler import GHandler\n",
    "import importlib\n",
    "importlib.reload(GHandler)\n",
    "from llm_handler.GHandler import GHandler\n",
    "\n",
    "import pandas as pd\n",
    "tabs = pd.ExcelFile(db_path).sheet_names \n",
    "tabs = [sheet for sheet in tabs if \"TEST\" in sheet]\n",
    "print(tabs)\n",
    "# df = pd.read_excel(db_path, sheet_name=sheet_name)\n",
    "# # need to embed the day_trips_df\n",
    "# day_trips_df[\"Text\"] = day_trips_df.apply(lambda row: f\"Activity: {row['Activity']}, Location: {row['Location']}, Category: {row['Category']} Price: {row['Price']}\", axis=1)\n",
    "\n",
    "\n",
    "# g_handler = GHandler(GEMINI_API_KEY)\n",
    "# df_embedded = g_handler.embed_df(day_trips_df,\n",
    "#                                  title = \"Activity\", \n",
    "#                                  text = \"Text\",\n",
    "#                                  model=\"models/embedding-001\")\n",
    "# daytrip_recommendation = g_handler.find_best_passage(g_response.text, df_embedded)\n",
    "# print(daytrip_recommendation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Cascade Recommendation Engine\n",
    "\n",
    "Given the user's primary match, the recommendation engine will look up secondary and tertiary recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings for the hotels and flights\n",
    "flights_hotels_df = pd.read_excel(r'./database/travel/Data Model for Travel.xlsx', sheet_name=\"Hotels\")\n",
    "# drop where type == Nan\n",
    "flights_hotels_df = flights_hotels_df.dropna(subset=[\"Type\"])\n",
    "flights_hotels_df[\"Text\"] = flights_hotels_df.apply(lambda row: f\"Name: {row['Name']}, Type: {row['Type']}, Location: {row['Location']}, Price: {row['Price']}, Description: {row['Description']}\", axis=1)\n",
    "\n",
    "\n",
    "g_handler = GHandler(GEMINI_API_KEY)\n",
    "flights_hotels_df = g_handler.embed_df(flights_hotels_df,\n",
    "                                 title = \"Name\", \n",
    "                                 text = \"Text\",\n",
    "                                 model=\"models/embedding-001\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Convo_2 = f\"\"\"I have an inventory for a {daytrip_recommendation}. I can recommend you a more luxurious based on the location of the activity.\"\"\"\n",
    "hotel_recommendation = g_handler.find_best_passage(Convo_2, flights_hotels_df)\n",
    "print(hotel_recommendation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Convo_3 = f\"\"\"I have an inventory for a {daytrip_recommendation}. I can recommend you the longest flight based on the location of the activity.\"\"\"\n",
    "flight_recommendation = g_handler.find_best_passage(Convo_3, flights_hotels_df)\n",
    "print(flight_recommendation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_hotels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper that inserts\n",
    "# daytrip + hotel + flight into a 3 day 2 night itenerary\n",
    "# so first day fill with casual eating and sightseeing, then 2nd day is the daytrip focus, and 3rd day is the return flight\n",
    "# LLM has to be smart enough to infer duration of daytrip (hiking mt rinjani is 2 days, so it should be 2 days 1 night)\n",
    "\n",
    "# Eg: himalayas\n",
    "# has to account for weather, seasons, and other factors that might affect the trip duration. Or postpone trip under more optimal factors\n",
    "# TESTCASE: NO inventory for customer request\n",
    "# TESTCASE: transport types (ferries, etc)\n",
    "\n",
    "# look at all factor buckets that involves inventory \n",
    "# Buckets to quantify the inventory\n",
    "# main factor is affiliation, services (driver, villa-cook, guide, translator), then location, then price, then type, then rating, then availability, then duration, then weather, then season, then other factors)\n",
    "# if not affiliated then shouldnt be recommended \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top n recommendations (pro consumer vs pro business)\n",
    "\n",
    "# need to see if they have existing monetisation strategy for their travel packages\n",
    "# recommmendations should be tailored to their monetisation strategy\n",
    "# (eg: if they have a partnership with a hotel, then recommend that hotel)\n",
    "\n",
    "\n",
    "# main objective: recommendation engine \n",
    "# warning: no buckets for existing monetisation strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daytrip_recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UX_prompt = f\"\"\"\n",
    "Generate a travel package for the given trip_recommendation:\n",
    "{daytrip_recommendation}\n",
    "\n",
    "This trip_recommendation comes with the following hotel recommendation:\n",
    "{hotel_recommendation}\n",
    "\n",
    "This trip_recommendation comes with the following flight recommendation:\n",
    "{flight_recommendation}\n",
    "\n",
    "The package should include the following sections:\n",
    "\n",
    "\"Summary\"\n",
    "introductory and summary of the trip in one paragraph.\n",
    "The summary should describe in vivid detail, the main attractions, activities, and experiences that the travelers can enjoy in the trip_recommendation. \n",
    "\n",
    "\"Journey Highlights\"\n",
    "A list of the main features and most exciting aspects of the package.\n",
    "the highlights must end off with a bold line: \"Your journey takes you to: x - y - z\"\n",
    "\n",
    "\"Itinerary & Map\" \n",
    "This section is an itenerary list that shows the day-by-day plan of the trip, that is also accompanied by a map.\n",
    "\n",
    "The itinerary should include the name, location, and description of each place or activity that the travelers will visit or do each day. \n",
    "The itinerary should also indicate the approximate duration and transportation mode for each item.\n",
    "\n",
    "A highlights and inclusions section that lists the main features and benefits of the package. \n",
    "The section should mention what is included in the price, such as flights, accommodation, meals, guides, entrance fees, etc. \n",
    "The section should also mention any special offers or discounts that are available for the package.\n",
    "A dates and pricing section that shows the available dates and prices for the package. \n",
    "The section should indicate the departure and return dates, the number of travelers, the total cost, and the payment options for the package. \n",
    "The section should also provide a link or contact information for booking or inquiring about the package.\n",
    "\n",
    "All information derived here should be based on the recommendations from the previous steps and MUST not be fabricated.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from settings import GEMINI_API_KEY\n",
    "from llm_handler.GHandler import GHandler\n",
    "\n",
    "g_handler = GHandler(GEMINI_API_KEY)\n",
    "\n",
    "response_UX = g_handler.prompt(UX_prompt)\n",
    "print(response_UX.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format mimic from image of travel website package page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./database/travel/lux_example.jpg\"\n",
    "prompt_1 = f\"\"\"Reproduce the format of this travel package given a different destination: \n",
    "Generate a travel package for the given trip_recommendation:\n",
    "{daytrip_recommendation}\n",
    "\n",
    "This trip_recommendation comes with the following hotel recommendation:\n",
    "{hotel_recommendation}\n",
    "\n",
    "This trip_recommendation comes with the following flight recommendation:\n",
    "{flight_recommendation}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from IPython.display import Image, display\n",
    "# display(Image(filename=image_path))\n",
    "\n",
    "from settings import GEMINI_API_KEY\n",
    "from llm_handler.GHandler import GHandler\n",
    "\n",
    "g_handler = GHandler(GEMINI_API_KEY)\n",
    "\n",
    "g_response = g_handler.prompt_image(model_name = \"gemini-pro-vision\",\n",
    "                                  image_path = image_path,\n",
    "                                  prompt_1 = prompt_1,\n",
    "                                  prompt_2 = None)\n",
    "print(g_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e) Full Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Field populator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = \"\"\"\n",
    "\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tACCOMMODATION ARRANGMENTS\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tNUMBER OF PAX\t\t\t\t\t\t\t\tTRAVEL INSURANCE\t\t\t\t\t\t\t\t\tVISA ARRANGEMENTS\t\t\t\t\t\t\t\t\tBESPOKE VIP SERVICES\t\t\t\t\t\t\tENTIRE TRIP GRAND TOTAL (MYR)\n",
    "ITEM\tCLIENTELE\t\t\t\t\t\t\t\t\t\t\t\t\tGENERAL BIODATA\t\t\t\t\t\t\t\t\tCLIENT DIRECT BOOKING\t\t\t\t\t\t\tPIC/BOOKER\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tTRIP\t\t\t\t\t\t\tPURCHASE TYPE\t\t\t\t\t\t\tFLIGHT ARRANGEMENTS\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tB2B PLATFORM\tDESTINATION\tGROUP\tPROPERTY TYPE\tHOTEL BRAND\tSTAR RATING\tTRAVEL DATE\tPERIOD OF STAY (NUMBER OF NIGHTS)\tROOM CATEGORY\tROOM CONFIGURATION (BED-TYPE)\tROOM UNITS\tROOM OCCUPANCY (NUMBER OF GUESTS)\tROOM RATE WITH BREAKFAST/NIGHT (MYR)\t\tROOM-ONLY RATE /NIGHT (MYR)\t\tGRAND TOTAL\t\"ADULT \n",
    "(12 YEARS OLD AND ABOVE)\"\t\"CHILD\n",
    "(INFANT - 11 YEARS OLD)\"\t\tDOMESTIC HELPER\t\tSTAFF\tBODYGUARD\tPOLICE ESCORT\tINSURANCE COMPANY\tINSURANCE TYPE\tINSURANCE PLAN\tTRIP PLAN\tPOLICY NUMBER\tPERIOD OF COVERAGE\tCOST\tSELLING\tCOUNTRIES WE COVER\tVISA TYPE\tVISA CATEGORY\tAPPLICANT NAME\tREFERENCE NUMBER\tPERIOD OF STAY\tINSURED BY\tCOST PER PERSON\tMARK UP RATE (MYR)\tSELLING RATE PER PERSON\tMEET & GREET\tAIRPORT DUTY\tBUGGY ASSISTANCE\tLUGGAGE WRAP SERVICE\tSPECIAL CARE ASSISTANCE\tVIP LOUNGE\tSMART WORLD ALLOWANCE TO STAFF\t\n",
    "\tCLIENT ID\tORGANIZATION\tSEGMENT\tREMARK\tPREFIX\tTITLE\tFULL NAME\tDESIGNATION | OCCUPATION\tRELATIONSHIP\tCLIENT ID\tCOMPANY\tBUSINESS ADDRESS\tREGION\tBIRTH DATE\tPASSPORT NUMBER\tIDENTIFICATION NUMBER\tMARITAL STATUS\tGENDER\tAGE\tRACE\tNATIONALITY \tRELIGION\tCLIENT TYPE\t\"CLIENT SINCE\n",
    "(YEAR)\"\tEMAIL ADDRESS\tCOUNTRY CODE\tPHONE\tCOUNTRY CODE\tMOBILE\tPREFIX\tTITLE\tBOOKER NAME\tDESIGNATION/OCCUPATION\tRELATIONSHIP\tCLIENT ID\tDEPARTMENT\tCOMPANY\tBUSINESS ADDRESS\tREGION\tEMAIL ADDRESS\tCOUNTRY CODE\tPHONE\tCOUNTRY CODE\tMOBILE\tCLIENT SPENDING POWER\tPURPOSE OF TRAVEL\tTRAVEL TYPE\tOCCASION\tFAMILY COMPOSITION\t\"DATE OF TRAVEL\n",
    "(DD.MM.YY - DD.MM.YY)\"\tLENGTH OF TRAVEL (DAY)\tFLIGHT\tACCOMMODATION\tTRANSPORTATION\tVIP SERVICE\tVISA\tTRAVEL INSURANCE\tTOUR PACKAGE\tTRIP NAME\tAIRLINE NAME\tCATEGORY\tDESTINATION\tDOMESTIC FLIGHT\tINTERNATIONAL FLIGHT\tONE WAY TRIP\tRETURN TICKET\tDEPARTURE DATE\tDEPARTURE TIME\tARRIVAL DATE\tARRIVAL TIME\tCOST\tMARK UP RATE\tSELLING\t\t\t\t\t\t\t\t\t\t\t\t\tCOST ROOM RATE PER NIGHT WITH BREAKFAST (MYR)\tSELLING ROOM RATE PER NIGHT WITH BREAKFAST (MYR)\tCOST ROOM-ONLY RATE PER NIGHT (MYR)\tSELLING ROOM -ONLY RATE PER NIGHT (MYR)\t\t\t\t\tNATIONALITY\tPAX\t\t\t\t\t\t\t\t\t\t\t\tCLUSTER | DESTINATION\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./database/travel/travel_itinerary.jpg\"\n",
    "prompt_1 = \"From this picture of a travel itinerary\"\n",
    "prompt_2 = \"Based on the response, recommend a full day trip travel itinerary\"\n",
    "from IPython.display import Image, display\n",
    "display(Image(filename=image_path))\n",
    "\n",
    "from settings import GEMINI_API_KEY\n",
    "from llm_handler.GHandler import GHandler\n",
    "\n",
    "g_handler = GHandler(GEMINI_API_KEY)\n",
    "\n",
    "g_response = g_handler.prompt_image(model_name = \"gemini-pro-vision\",\n",
    "                                  image_path = image_path,\n",
    "                                  prompt_1 = prompt_1,\n",
    "                                  prompt_2 = prompt_2)\n",
    "print(g_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Process Flow\n",
    "0) customer request \n",
    "-  \n",
    "\n",
    "1) Flight booking\n",
    "- SABRE \n",
    "- This must be determined first, \n",
    "\n",
    "\n",
    "2) Hotel: B2B platforms: \n",
    "- WithinEarth\n",
    "- TBO\n",
    "- RAtehawk \n",
    "- booking.com \n",
    "\n",
    "\n",
    "tour package\n",
    "- DMC partner lag (24 - 48hours) \n",
    "\n",
    "DMC partners need to be filtered, \n",
    "\n",
    "proposal:  0.5 days, finalis, another half of the day - hanis will compile\n",
    "- check flight first, ticketing then hotel. \n",
    "STANDARD: 24-48 hours within proposal to get invoice. \n",
    "\n",
    "proposals usually take 24 hours, \n",
    "\n",
    "invoice, confirmed, wit client then draft of the invoice, --> to finance, and client. \n",
    "- depends on payment terms, if they have add on services, then invoice will be sent after trip. \n",
    "- mostly high profile boss, but no penalty. penalty 1.2% ---> 15% pay upfreont, another 10% credit term, 5% deposit, 75% the rest after \n",
    "\n",
    "\n",
    "\n",
    "mostly the same for umrah. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
